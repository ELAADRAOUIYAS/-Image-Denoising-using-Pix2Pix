{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":257.45146,"end_time":"2021-10-29T05:47:50.972309","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2021-10-29T05:43:33.520849","version":"2.3.3"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4406,"databundleVersionId":34170,"sourceType":"competition"}],"dockerImageVersionId":30553,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport zipfile\nimport os\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, Input\nfrom tensorflow.keras.callbacks import EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2023-08-31T13:08:34.977045Z","iopub.execute_input":"2023-08-31T13:08:34.977485Z","iopub.status.idle":"2023-08-31T13:08:52.545529Z","shell.execute_reply.started":"2023-08-31T13:08:34.977457Z","shell.execute_reply":"2023-08-31T13:08:52.544538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# path to zipped & working directories\npath_zip = '/kaggle/input/denoising-dirty-documents/'\npath = '/kaggle/working/'\n\n# unzip files first to working directory\n# We could use also unzipped data source, but why not to learn something new?\nwith zipfile.ZipFile(path_zip + 'train.zip', 'r') as zip_ref:\n    zip_ref.extractall(path)\n\nwith zipfile.ZipFile(path_zip + 'test.zip', 'r') as zip_ref:\n    zip_ref.extractall(path)  \n    \nwith zipfile.ZipFile(path_zip + 'train_cleaned.zip', 'r') as zip_ref:\n    zip_ref.extractall(path)  \n    \nwith zipfile.ZipFile(path_zip + 'sampleSubmission.csv.zip', 'r') as zip_ref:\n    zip_ref.extractall(path)  ","metadata":{"papermill":{"duration":2.146257,"end_time":"2021-10-29T05:43:49.418610","exception":false,"start_time":"2021-10-29T05:43:47.272353","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-31T13:08:56.826199Z","iopub.execute_input":"2023-08-31T13:08:56.827007Z","iopub.status.idle":"2023-08-31T13:08:59.076296Z","shell.execute_reply.started":"2023-08-31T13:08:56.826970Z","shell.execute_reply":"2023-08-31T13:08:59.075254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# store image names in list for later use\ntrain_img = sorted(os.listdir(path + '/train'))\ntrain_cleaned_img = sorted(os.listdir(path + '/train_cleaned'))\ntest_img = sorted(os.listdir(path + '/test'))","metadata":{"papermill":{"duration":0.02015,"end_time":"2021-10-29T05:43:49.450568","exception":false,"start_time":"2021-10-29T05:43:49.430418","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-31T13:09:02.744030Z","iopub.execute_input":"2023-08-31T13:09:02.744512Z","iopub.status.idle":"2023-08-31T13:09:02.753022Z","shell.execute_reply.started":"2023-08-31T13:09:02.744474Z","shell.execute_reply":"2023-08-31T13:09:02.751804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare function\ndataset_path = \"/kaggle/working/train\"\ndef process_image(path):\n    img = cv2.imread(path)\n    img = np.asarray(img, dtype=\"float32\")\n    img = cv2.resize(img, (540, 420))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img = img/255.0\n    img = np.reshape(img,(420, 540, 1))\n    \n    return img","metadata":{"papermill":{"duration":0.019459,"end_time":"2021-10-29T05:43:49.481530","exception":false,"start_time":"2021-10-29T05:43:49.462071","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-31T13:09:05.735207Z","iopub.execute_input":"2023-08-31T13:09:05.735631Z","iopub.status.idle":"2023-08-31T13:09:05.743410Z","shell.execute_reply.started":"2023-08-31T13:09:05.735598Z","shell.execute_reply":"2023-08-31T13:09:05.742496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preprocess images\ntrain = []\ntrain_cleaned = []\ntest = []\n\nfor f in sorted(os.listdir(path + 'train/')):\n    train.append(process_image(path + 'train/' + f))\n\nfor f in sorted(os.listdir(path + 'train_cleaned/')):\n    train_cleaned.append(process_image(path + 'train_cleaned/' + f))\n   \nfor f in sorted(os.listdir(path + 'test/')):\n    test.append(process_image(path + 'test/' + f))","metadata":{"papermill":{"duration":2.344855,"end_time":"2021-10-29T05:43:51.837891","exception":false,"start_time":"2021-10-29T05:43:49.493036","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-31T13:09:08.848073Z","iopub.execute_input":"2023-08-31T13:09:08.848451Z","iopub.status.idle":"2023-08-31T13:09:10.647338Z","shell.execute_reply.started":"2023-08-31T13:09:08.848419Z","shell.execute_reply":"2023-08-31T13:09:10.646221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,25))\nfor i in range(0,8,2):\n    plt.subplot(4,2,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(train[i][:,:,0], cmap='gray')\n    plt.title('Noise image: {}'.format(train_img[i]))\n    \n    plt.subplot(4,2,i+2)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(train_cleaned[i][:,:,0], cmap='gray')\n    plt.title('Denoised image: {}'.format(train_img[i]))\n\nplt.show()","metadata":{"papermill":{"duration":1.130741,"end_time":"2021-10-29T05:43:52.980871","exception":false,"start_time":"2021-10-29T05:43:51.850130","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-31T13:09:13.098057Z","iopub.execute_input":"2023-08-31T13:09:13.098436Z","iopub.status.idle":"2023-08-31T13:09:14.733587Z","shell.execute_reply.started":"2023-08-31T13:09:13.098402Z","shell.execute_reply":"2023-08-31T13:09:14.732276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert list to numpy array\nX_train = np.asarray(train)\ny_train = np.asarray(train_cleaned)\nX_test = np.asarray(test)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15)","metadata":{"execution":{"iopub.status.busy":"2023-08-31T13:09:20.505812Z","iopub.execute_input":"2023-08-31T13:09:20.506189Z","iopub.status.idle":"2023-08-31T13:09:20.693412Z","shell.execute_reply.started":"2023-08-31T13:09:20.506154Z","shell.execute_reply":"2023-08-31T13:09:20.692182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv_autoencoder = Sequential()\n\n# Encoder\nconv_autoencoder.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(420,540,1), activation='relu', padding='same'))\nconv_autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n\nconv_autoencoder.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='same'))\nconv_autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n\n\n\n# Decoder\nconv_autoencoder.add(Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='same'))\nconv_autoencoder.add(Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'))\n\n\n# Output\nconv_autoencoder.add(Conv2D(filters=1, kernel_size=(3,3), activation='sigmoid', padding='same'))\n\nconv_autoencoder.summary()","metadata":{"execution":{"iopub.status.busy":"2023-08-31T13:09:23.715556Z","iopub.execute_input":"2023-08-31T13:09:23.716155Z","iopub.status.idle":"2023-08-31T13:09:29.440993Z","shell.execute_reply.started":"2023-08-31T13:09:23.716113Z","shell.execute_reply":"2023-08-31T13:09:29.439983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install wandb","metadata":{"execution":{"iopub.status.busy":"2023-08-31T13:09:35.221176Z","iopub.execute_input":"2023-08-31T13:09:35.221639Z","iopub.status.idle":"2023-08-31T13:09:49.151784Z","shell.execute_reply.started":"2023-08-31T13:09:35.221603Z","shell.execute_reply":"2023-08-31T13:09:49.150354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\nfrom wandb.keras import WandbMetricsLogger, WandbModelCheckpoint","metadata":{"execution":{"iopub.status.busy":"2023-08-31T13:09:52.364212Z","iopub.execute_input":"2023-08-31T13:09:52.365226Z","iopub.status.idle":"2023-08-31T13:09:53.403762Z","shell.execute_reply.started":"2023-08-31T13:09:52.365182Z","shell.execute_reply":"2023-08-31T13:09:53.402629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.login()","metadata":{"execution":{"iopub.status.busy":"2023-08-31T13:09:56.352814Z","iopub.execute_input":"2023-08-31T13:09:56.353196Z","iopub.status.idle":"2023-08-31T13:10:06.984293Z","shell.execute_reply.started":"2023-08-31T13:09:56.353163Z","shell.execute_reply":"2023-08-31T13:10:06.983256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom wandb.keras import WandbCallback\n\n# Initialize WandB\nwandb.init(project='task1-conv-autoencoder', name='Image_Pre')\n\n# Compile the model\nconv_autoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\n\n# Define the early stopping callback\nearly_stop = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n\n# Train the model\nhistory = conv_autoencoder.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=500, batch_size=16, callbacks=[early_stop, WandbCallback()])\n\n# Save the model architecture as JSON\nmodel_json = conv_autoencoder.to_json()\nwith open(\"model_architecture.json\", \"w\") as json_file:\n    json_file.write(model_json)\n\n# Log the model architecture\nwandb.save(\"model_architecture.json\")\n\n# Log the model summary\nconv_autoencoder.summary(print_fn=lambda x: wandb.log({\"model_summary\": x}))\n\n# Finish the run\nwandb.run.finish()","metadata":{"execution":{"iopub.status.busy":"2023-08-31T13:10:10.383552Z","iopub.execute_input":"2023-08-31T13:10:10.384232Z","iopub.status.idle":"2023-08-31T13:28:37.112410Z","shell.execute_reply.started":"2023-08-31T13:10:10.384197Z","shell.execute_reply":"2023-08-31T13:28:37.111636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check how loss & mae went down\nepoch_loss = history.history['loss']\nepoch_val_loss = history.history['val_loss']\nepoch_mae = history.history['mse']\nepoch_val_mae = history.history['val_mse']\n\nplt.figure(figsize=(20,6))\nplt.subplot(1,2,1)\nplt.plot(range(0,len(epoch_loss)), epoch_loss, 'b-', linewidth=2, label='Train Loss')\nplt.plot(range(0,len(epoch_val_loss)), epoch_val_loss, 'r-', linewidth=2, label='Val Loss')\nplt.title('Evolution of loss on train & validation datasets over epochs')\nplt.legend(loc='best')\n\nplt.subplot(1,2,2)\nplt.plot(range(0,len(epoch_mae)), epoch_mae, 'b-', linewidth=2, label='Train MSE')\nplt.plot(range(0,len(epoch_val_mae)), epoch_val_mae, 'r-', linewidth=2,label='Val MSE')\nplt.title('Evolution of MSE on train & validation datasets over epochs')\nplt.legend(loc='best')\n\nplt.show()","metadata":{"papermill":{"duration":0.991239,"end_time":"2021-10-29T05:46:22.301322","exception":false,"start_time":"2021-10-29T05:46:21.310083","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-31T13:29:44.988448Z","iopub.execute_input":"2023-08-31T13:29:44.988848Z","iopub.status.idle":"2023-08-31T13:29:45.517204Z","shell.execute_reply.started":"2023-08-31T13:29:44.988810Z","shell.execute_reply":"2023-08-31T13:29:45.516247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = conv_autoencoder.predict(X_test, batch_size=16)","metadata":{"papermill":{"duration":1.180306,"end_time":"2021-10-29T05:46:24.077809","exception":false,"start_time":"2021-10-29T05:46:22.897503","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-31T13:29:51.576422Z","iopub.execute_input":"2023-08-31T13:29:51.577435Z","iopub.status.idle":"2023-08-31T13:29:53.158359Z","shell.execute_reply.started":"2023-08-31T13:29:51.577383Z","shell.execute_reply":"2023-08-31T13:29:53.157221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\n\n# Start the timer\nstart_time = time.time()\n\n# Your task code here\nplt.figure(figsize=(8, 4))\nplt.subplot(1, 2, 1)\nplt.xticks([])\nplt.yticks([])\nplt.imshow(X_test[0][:, :, 0], cmap='gray')\nplt.title('Noisy Image: {}'.format(test_img[0]))\n\nplt.subplot(1, 2, 2)\nplt.xticks([])\nplt.yticks([])\nplt.imshow(y_pred[0][:, :, 0], cmap='gray')\nplt.title('Denoised Image: {}'.format(test_img[0]))\n\nplt.tight_layout()\nplt.show()\n\n# Calculate the elapsed time\nelapsed_time = time.time() - start_time\nprint(\"Time taken: {:.2f} seconds\".format(elapsed_time))\n","metadata":{"execution":{"iopub.status.busy":"2023-08-31T13:29:55.969868Z","iopub.execute_input":"2023-08-31T13:29:55.970239Z","iopub.status.idle":"2023-08-31T13:29:56.349116Z","shell.execute_reply.started":"2023-08-31T13:29:55.970206Z","shell.execute_reply":"2023-08-31T13:29:56.348168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,25))\nfor i in range(0,8,2):\n    plt.subplot(4,2,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(X_test[i][:,:,0], cmap='gray')\n    plt.title('Noisy image: {}'.format(test_img[i]))\n    \n    plt.subplot(4,2,i+2)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(y_pred[i][:,:,0], cmap='gray')\n    plt.title('Denoised by autoencoder: {}'.format(test_img[i]))\n\nplt.show()","metadata":{"papermill":{"duration":1.417256,"end_time":"2021-10-29T05:46:26.060390","exception":false,"start_time":"2021-10-29T05:46:24.643134","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-08-31T13:30:03.502070Z","iopub.execute_input":"2023-08-31T13:30:03.502502Z","iopub.status.idle":"2023-08-31T13:30:05.230111Z","shell.execute_reply.started":"2023-08-31T13:30:03.502464Z","shell.execute_reply":"2023-08-31T13:30:05.229257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# To adapt the model to handle large images, we will implement the sliding window technique.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport cv2\n\ndef add_padding(image, window_size, stride):\n    h, w = image.shape[:2]\n    pad_h = (stride - (h - window_size[0]) % stride) % stride\n    pad_w = (stride - (w - window_size[1]) % stride) % stride\n    padded_image = cv2.copyMakeBorder(image, 0, pad_h, 0, pad_w, cv2.BORDER_CONSTANT, value=255)\n    return padded_image\n\n\ndef sliding_window(image, window_size, stride):\n    h, w = image.shape[:2]\n    for y in range(0, h - window_size[0] + 1, stride):\n        for x in range(0, w - window_size[1] + 1, stride):\n            yield x, y, image[y:y + window_size[0], x:x + window_size[1]]\n\n\ndef test_model_on_large_image(model, large_image_path, window_size, stride):\n    large_image = cv2.imread(large_image_path, cv2.IMREAD_GRAYSCALE)\n    padded_image = add_padding(large_image, window_size, stride)\n    \n    output_image = np.zeros_like(padded_image, dtype=np.float32)  # Specify float32 data type\n    count_map = np.zeros_like(padded_image)\n\n    for x, y, window in sliding_window(padded_image, window_size, stride):\n        window = np.expand_dims(window, axis=-1)\n        prediction = model.predict(np.expand_dims(window,axis=0))\n\n        output_image[y:y + window_size[0], x:x + window_size[1]] += prediction[0,:,:,0].astype(np.float32)\n\n        count_map[y:y + window_size[0], x:x + window_size[1]] += 1\n\n    # Clip the output_image to the range [0, 255] and convert it back to uint8\n    output_image = np.clip(output_image / count_map , 0 , 255).astype(np.uint8)\n\n    # Remove padding by cropping to the original size\n    pad_h = (stride - (large_image.shape[0] - window_size[0]) % stride) % stride\n    pad_w = (stride - (large_image.shape[1] - window_size[1]) % stride) % stride\n    output_image = output_image[:large_image.shape[0]+pad_h,:large_image.shape[1]+pad_w]\n\n    return output_image\n","metadata":{"execution":{"iopub.status.busy":"2023-08-31T14:20:41.686479Z","iopub.execute_input":"2023-08-31T14:20:41.686909Z","iopub.status.idle":"2023-08-31T14:20:41.702674Z","shell.execute_reply.started":"2023-08-31T14:20:41.686869Z","shell.execute_reply":"2023-08-31T14:20:41.701516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"large_image_path=\"/kaggle/input/image6/6.jpeg\"","metadata":{"execution":{"iopub.status.busy":"2023-08-31T14:12:17.189576Z","iopub.execute_input":"2023-08-31T14:12:17.189966Z","iopub.status.idle":"2023-08-31T14:12:17.194919Z","shell.execute_reply.started":"2023-08-31T14:12:17.189932Z","shell.execute_reply":"2023-08-31T14:12:17.193841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\n\n# Load the image using OpenCV\nimage_path =\"/kaggle/input/image6/6.jpeg\"\nimage = cv2.imread(image_path)\n\n# Get the height and width of the image\nheight, width = image.shape[:2]\n\n# Print the size of the image\nprint(f\"Image size: {width}x{height}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-08-31T13:52:46.093293Z","iopub.execute_input":"2023-08-31T13:52:46.093784Z","iopub.status.idle":"2023-08-31T13:52:46.124644Z","shell.execute_reply.started":"2023-08-31T13:52:46.093749Z","shell.execute_reply":"2023-08-31T13:52:46.123516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_image = test_model_on_large_image(conv_autoencoder, large_image_path, target_size=(1300,1060), window_size=(420,540), stride=420)","metadata":{"execution":{"iopub.status.busy":"2023-08-31T13:44:33.712815Z","iopub.execute_input":"2023-08-31T13:44:33.713194Z","iopub.status.idle":"2023-08-31T13:44:34.136832Z","shell.execute_reply.started":"2023-08-31T13:44:33.713163Z","shell.execute_reply":"2023-08-31T13:44:34.135657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_image = test_model_on_large_image(conv_autoencoder, large_image_path, window_size=(420,540), stride=30)","metadata":{"execution":{"iopub.status.busy":"2023-08-31T14:22:18.476961Z","iopub.execute_input":"2023-08-31T14:22:18.477471Z","iopub.status.idle":"2023-08-31T14:22:48.274580Z","shell.execute_reply.started":"2023-08-31T14:22:18.477432Z","shell.execute_reply":"2023-08-31T14:22:48.273316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original_img=large_image_path\norigi=cv2.imread(original_img, cv2.IMREAD_GRAYSCALE)","metadata":{"execution":{"iopub.status.busy":"2023-08-31T14:23:07.654870Z","iopub.execute_input":"2023-08-31T14:23:07.655274Z","iopub.status.idle":"2023-08-31T14:23:07.674669Z","shell.execute_reply.started":"2023-08-31T14:23:07.655240Z","shell.execute_reply":"2023-08-31T14:23:07.673771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove padding by cropping to the original size (exclude black areas at the right and bottom)\noutput_image = output_image[:origi.shape[0], :origi.shape[1]]\n\n# Display the original and output images side by side with their original sizes\nplt.figure(figsize=(10, 5))  # Adjust the figure size as needed\n\n# Original image subplot\nplt.subplot(1, 2, 1)  # 1 row, 2 columns, subplot index 1\nplt.imshow(origi, cmap='gray', aspect='auto')  # Set aspect to 'auto' to preserve the original aspect ratio\nplt.title('Original Image')\nplt.axis('off')  # Turn off axes for a cleaner display\n\n# Output image subplot\nplt.subplot(1, 2, 2)  # 1 row, 2 columns, subplot index 2\nplt.imshow(output_image, cmap='gray', aspect='auto')  # Set aspect to 'auto' to preserve the original aspect ratio\nplt.title('SCanned Image')\nplt.axis('off')  # Turn off axes for a cleaner display\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-31T14:23:15.765375Z","iopub.execute_input":"2023-08-31T14:23:15.765831Z","iopub.status.idle":"2023-08-31T14:23:16.367564Z","shell.execute_reply.started":"2023-08-31T14:23:15.765790Z","shell.execute_reply":"2023-08-31T14:23:16.366556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 5))  # Adjust the figure size as needed\n\n# Original image subplot\nplt.subplot(1, 2, 1)  # 1 row, 2 columns, subplot index 1\nplt.imshow(origi, cmap='gray')\nplt.title('Original Image')\nplt.axis('off')  # Turn off axes for a cleaner display\n\n# Output image subplot\nplt.subplot(1, 2, 2)  # 1 row, 2 columns, subplot index 2\nplt.imshow(output_image, cmap='gray')\nplt.title('Output Image')\nplt.axis('off')  # Turn off axes for a cleaner display\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-31T14:23:25.090541Z","iopub.execute_input":"2023-08-31T14:23:25.090923Z","iopub.status.idle":"2023-08-31T14:23:25.516186Z","shell.execute_reply.started":"2023-08-31T14:23:25.090890Z","shell.execute_reply":"2023-08-31T14:23:25.515228Z"},"trusted":true},"execution_count":null,"outputs":[]}]}